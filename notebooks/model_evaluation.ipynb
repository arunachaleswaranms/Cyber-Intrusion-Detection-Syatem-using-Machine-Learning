{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation for Intrusion Detection System\n",
    "\n",
    "This notebook covers the steps for loading trained models, evaluating their performance on the test dataset, and generating evaluation reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data\n",
    "\n",
    "We'll load the preprocessed test dataset from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed test dataset\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_test = pd.read_csv('y_test.csv').values.ravel()\n",
    "\n",
    "# Display the shape of the dataset\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Models\n",
    "\n",
    "We'll load the previously trained Random Forest and Gradient Boosting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained models\n",
    "rf_model = joblib.load('random_forest_model.joblib')\n",
    "gb_model = joblib.load('gradient_boosting_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Models\n",
    "\n",
    "We'll evaluate the models on the test set and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9431372549019608, 0.9488888888888889)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "rf_test_preds = rf_model.predict(X_test)\n",
    "gb_test_preds = gb_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "rf_accuracy = accuracy_score(y_test, rf_test_preds)\n",
    "gb_accuracy = accuracy_score(y_test, gb_test_preds)\n",
    "\n",
    "rf_accuracy, gb_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Reports\n",
    "\n",
    "We'll generate classification reports for both models to evaluate their performance in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.97      0.99      0.98      7460\\n           1       0.99      0.98      0.98      7840\\n\\n    accuracy                           0.98     15300\\n   macro avg       0.98      0.98      0.98     15300\\nweighted avg       0.98      0.98      0.98     15300\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate classification reports\n",
    "rf_class_report = classification_report(y_test, rf_test_preds)\n",
    "gb_class_report = classification_report(y_test, gb_test_preds)\n",
    "\n",
    "rf_class_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrices\n",
    "\n",
    "We'll generate confusion matrices to visualize the performance of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrices\n",
    "rf_conf_matrix = confusion_matrix(y_test, rf_test_preds)\n",
    "gb_conf_matrix = confusion_matrix(y_test, gb_test_preds)\n",
    "\n",
    "# Plot confusion matrices\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.heatmap(rf_conf_matrix, annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
    "ax[0].set_title('Random Forest Confusion Matrix')\n",
    "ax[0].set_xlabel('Predicted')\n",
    "ax[0].set_ylabel('Actual')\n",
    "\n",
    "sns.heatmap(gb_conf_matrix, annot=True, fmt='d', cmap='Blues', ax=ax[1])\n",
    "ax[1].set_title('Gradient Boosting Confusion Matrix')\n",
    "ax[1].set_xlabel('Predicted')\n",
    "ax[1].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "1. Loaded the preprocessed test dataset.\n",
    "2. Loaded the previously trained Random Forest and Gradient Boosting models.\n",
    "3. Evaluated the models on the test set and compared their performance.\n",
    "4. Generated classification reports and confusion matrices to evaluate the models in detail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
